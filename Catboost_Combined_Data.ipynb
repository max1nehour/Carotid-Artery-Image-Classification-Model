{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max1nehour/Carotid-Artery-Image-Classification-Model/blob/main/Catboost_Combined_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8066a09",
      "metadata": {
        "id": "d8066a09"
      },
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5639e0a",
      "metadata": {
        "id": "a5639e0a"
      },
      "outputs": [],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba8026b",
      "metadata": {
        "id": "eba8026b"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn==1.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02aad030",
      "metadata": {
        "id": "02aad030"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5d4fe4",
      "metadata": {
        "id": "2c5d4fe4"
      },
      "outputs": [],
      "source": [
        "pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e03b41a",
      "metadata": {
        "id": "6e03b41a",
        "outputId": "e219a969-fba6-48bd-c4a4-e9ec7ce08d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory used: 58.96 MB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "# Get process memory info\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_info = process.memory_info()\n",
        "\n",
        "# Convert from bytes to MB\n",
        "memory_used_mb = memory_info.rss / 1024 ** 2\n",
        "\n",
        "print(f\"Memory used: {memory_used_mb:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a182695",
      "metadata": {
        "id": "8a182695"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split,  StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "from xgboost import plot_tree\n",
        "from numpy import sort\n",
        "from statistics import mean\n",
        "from scipy.stats import chi2_contingency\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d29b96e",
      "metadata": {
        "id": "3d29b96e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def find_plaque(severity):\n",
        "    if int(severity)>1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def print_feature(model, df):\n",
        "    features = model.feature_importances_\n",
        "\n",
        "    # 獲取列名並轉換為列表\n",
        "    gene_list = df\n",
        "\n",
        "    # 過濾掉重要性非常低的特徵\n",
        "    threshold = 0  # 設定過濾不重要特徵的門檻\n",
        "    indices = np.where(features > threshold)[0]\n",
        "    filtered_importances = features[indices]\n",
        "    filtered_feature_names = np.array(gene_list)[indices]\n",
        "\n",
        "    # 按重要性排序\n",
        "    sorted_idx = np.argsort(filtered_importances)[::-1]\n",
        "    filtered_importances = filtered_importances[sorted_idx]\n",
        "    filtered_feature_names = filtered_feature_names[sorted_idx]\n",
        "\n",
        "     # 创建 DataFrame\n",
        "    fs_df = pd.DataFrame({\n",
        "        'Feature Name': filtered_feature_names,\n",
        "        'Importance': filtered_importances\n",
        "    })\n",
        "\n",
        "    # 繪製帶有 hue 的條形圖\n",
        "    plt.figure(figsize=(6, 10))\n",
        "    sns.barplot(x=filtered_importances, y=filtered_feature_names, hue=filtered_importances, palette='crest', dodge=False)\n",
        "\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.title('Feature Importances')\n",
        "    plt.yticks(fontsize=11)\n",
        "    plt.legend(title='Importance Level')\n",
        "    plt.show()\n",
        "\n",
        "    return fs_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bea1202",
      "metadata": {
        "id": "4bea1202",
        "outputId": "2e75bc72-7c55-4d3a-a919-68267c65e49d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1490/1901660766.py:1: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('base_allplq.csv')\n",
            "/tmp/ipykernel_1490/1901660766.py:2: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df2 = pd.read_csv('follow_allplq.csv')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PA_UIKey                          0\n",
            "RCCA_MAX_FLOW                     8\n",
            "RCCA_AVG_FLOW                    20\n",
            "RCCA_MIN_FLOW                     6\n",
            "RCCA_MAX_AVG_FLOW                20\n",
            "RCCA_PULSE                       20\n",
            "RCCA_RESISTANCE                   6\n",
            "RCCA_DIAMETER                    10\n",
            "RCCA_STATUS                       6\n",
            "RCCA_IMT                         22\n",
            "RICA_MAX_FLOW                    12\n",
            "RICA_AVG_FLOW                    22\n",
            "RICA_MIN_FLOW                     8\n",
            "RICA_MAX_AVG_FLOW                22\n",
            "RICA_PULSE                       22\n",
            "RICA_RESISTANCE                  10\n",
            "RICA_DIAMETER                    32\n",
            "右ICA正常與否                          6\n",
            "LCCA_MAX_FLOW                    10\n",
            "LCCA_AVG_FLOW                    20\n",
            "LCCA_MIN_FLOW                     8\n",
            "LCCA_MAX_AVG_FLOW                20\n",
            "LCCA_PULSE                       20\n",
            "LCCA_RESISTANCE                  10\n",
            "LCCA_DIAMETER                    16\n",
            "左CCA正常與否                          6\n",
            "LCCA_IMT                         30\n",
            "LICA_MAX_FLOW                    12\n",
            "LICA_AVG_FLOW                    22\n",
            "LICA_MIN_FLOW                     8\n",
            "LICA_MAX_AVG_FLOW                22\n",
            "LICA_PULSE                       22\n",
            "LICA_RESISTANCE                  12\n",
            "LICA_DIAMETER                    30\n",
            "左ICA正常與否                          8\n",
            "SEX                               0\n",
            "AGE                               0\n",
            "DRK                              38\n",
            "HYPERTENSION_SELF               308\n",
            "GASTROESOPHAGEA_REFLUX_SELF     174\n",
            "DIABETES_SELF                   123\n",
            "SMK_EXPERIENCE                   11\n",
            "APOPLEXIA_SELF                  301\n",
            "CORONARY_ARTERY_DIS_SELF        300\n",
            "OTHER_HEART_DIS_SELF            303\n",
            "HYPERLIPIDEMIA_SELF             301\n",
            "Severity                        500\n",
            "FOLLOW                            0\n",
            "BMI                              20\n",
            "BODY_FAT_RATE                  1922\n",
            "BODY_WAISTLINE                   17\n",
            "SIT_1_SYSTOLIC_PRESSURE           6\n",
            "SIT_1_DIASTOLIC_PRESSURE          6\n",
            "SIT_2_SYSTOLIC_PRESSURE           6\n",
            "SIT_2_DIASTOLIC_PRESSURE          6\n",
            "SIT_1_HEARTBEAT_SPEED             5\n",
            "LDL_C                            32\n",
            "TG                               32\n",
            "T_CHO                            32\n",
            "dtype: int64\n",
            "(47750, 60)\n",
            "['PA_UIKey', 'RCCA_MAX_FLOW', 'RCCA_AVG_FLOW', 'RCCA_MIN_FLOW', 'RCCA_MAX_AVG_FLOW', 'RCCA_PULSE', 'RCCA_RESISTANCE', 'RCCA_DIAMETER', 'RCCA_STATUS', 'RCCA_IMT', 'RICA_MAX_FLOW', 'RICA_AVG_FLOW', 'RICA_MIN_FLOW', 'RICA_MAX_AVG_FLOW', 'RICA_PULSE', 'RICA_RESISTANCE', 'RICA_DIAMETER', '右ICA正常與否', 'LCCA_MAX_FLOW', 'LCCA_AVG_FLOW', 'LCCA_MIN_FLOW', 'LCCA_MAX_AVG_FLOW', 'LCCA_PULSE', 'LCCA_RESISTANCE', 'LCCA_DIAMETER', '左CCA正常與否', 'LCCA_IMT', 'LICA_MAX_FLOW', 'LICA_AVG_FLOW', 'LICA_MIN_FLOW', 'LICA_MAX_AVG_FLOW', 'LICA_PULSE', 'LICA_RESISTANCE', 'LICA_DIAMETER', '左ICA正常與否', 'SEX', 'AGE', 'DRK', 'HYPERTENSION_SELF', 'GASTROESOPHAGEA_REFLUX_SELF', 'DIABETES_SELF', 'SMK_EXPERIENCE', 'APOPLEXIA_SELF', 'CORONARY_ARTERY_DIS_SELF', 'OTHER_HEART_DIS_SELF', 'HYPERLIPIDEMIA_SELF', 'Severity', 'FOLLOW', 'BMI', 'BODY_FAT_RATE', 'BODY_WAISTLINE', 'SIT_1_SYSTOLIC_PRESSURE', 'SIT_1_DIASTOLIC_PRESSURE', 'SIT_2_SYSTOLIC_PRESSURE', 'SIT_2_DIASTOLIC_PRESSURE', 'SIT_1_HEARTBEAT_SPEED', 'LDL_C', 'TG', 'T_CHO', 'Plaque']\n",
            "PA_UIKey                       0\n",
            "RCCA_MAX_FLOW                  0\n",
            "RCCA_AVG_FLOW                  0\n",
            "RCCA_MIN_FLOW                  0\n",
            "RCCA_MAX_AVG_FLOW              0\n",
            "RCCA_PULSE                     0\n",
            "RCCA_RESISTANCE                0\n",
            "RCCA_DIAMETER                  0\n",
            "RCCA_STATUS                    0\n",
            "RCCA_IMT                       0\n",
            "RICA_MAX_FLOW                  0\n",
            "RICA_AVG_FLOW                  0\n",
            "RICA_MIN_FLOW                  0\n",
            "RICA_MAX_AVG_FLOW              0\n",
            "RICA_PULSE                     0\n",
            "RICA_RESISTANCE                0\n",
            "RICA_DIAMETER                  0\n",
            "右ICA正常與否                       0\n",
            "LCCA_MAX_FLOW                  0\n",
            "LCCA_AVG_FLOW                  0\n",
            "LCCA_MIN_FLOW                  0\n",
            "LCCA_MAX_AVG_FLOW              0\n",
            "LCCA_PULSE                     0\n",
            "LCCA_RESISTANCE                0\n",
            "LCCA_DIAMETER                  0\n",
            "左CCA正常與否                       0\n",
            "LCCA_IMT                       0\n",
            "LICA_MAX_FLOW                  0\n",
            "LICA_AVG_FLOW                  0\n",
            "LICA_MIN_FLOW                  0\n",
            "LICA_MAX_AVG_FLOW              0\n",
            "LICA_PULSE                     0\n",
            "LICA_RESISTANCE                0\n",
            "LICA_DIAMETER                  0\n",
            "左ICA正常與否                       0\n",
            "SEX                            0\n",
            "AGE                            0\n",
            "DRK                            0\n",
            "HYPERTENSION_SELF              0\n",
            "GASTROESOPHAGEA_REFLUX_SELF    0\n",
            "DIABETES_SELF                  0\n",
            "SMK_EXPERIENCE                 0\n",
            "APOPLEXIA_SELF                 0\n",
            "CORONARY_ARTERY_DIS_SELF       0\n",
            "OTHER_HEART_DIS_SELF           0\n",
            "HYPERLIPIDEMIA_SELF            0\n",
            "Severity                       0\n",
            "FOLLOW                         0\n",
            "BMI                            0\n",
            "BODY_FAT_RATE                  0\n",
            "BODY_WAISTLINE                 0\n",
            "SIT_1_SYSTOLIC_PRESSURE        0\n",
            "SIT_1_DIASTOLIC_PRESSURE       0\n",
            "SIT_2_SYSTOLIC_PRESSURE        0\n",
            "SIT_2_DIASTOLIC_PRESSURE       0\n",
            "SIT_1_HEARTBEAT_SPEED          0\n",
            "LDL_C                          0\n",
            "TG                             0\n",
            "T_CHO                          0\n",
            "Plaque                         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.read_csv('base_allplq.csv')\n",
        "df2 = pd.read_csv('follow_allplq.csv')\n",
        "df = pd.concat([df1, df2])\n",
        "df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     ,'SURVEY_DATE','Release_No','頸超總結'])\n",
        "pd.set_option('display.max_rows', None)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df['BODY_FAT_RATE'] = df['BODY_FAT_RATE'].fillna(df['BODY_FAT_RATE'].median())\n",
        "df = df.dropna()\n",
        "df['Plaque'] = df['Severity'].apply(lambda x: find_plaque(x))\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns.to_list())\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca4b234",
      "metadata": {
        "id": "3ca4b234",
        "outputId": "b4ab1ae1-c827-47d9-90a7-ad810e0c2cf6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'base' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m##################### ALL ARTERY TO ALL DIAGNOSIS #################\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Define Input/ Output (array type)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mbase\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_UIKey\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlaque\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeverity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFOLLOW\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRCCA_STATUS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m右ICA正常與否\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m左CCA正常與否\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m左ICA正常與否\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                      \u001b[38;5;66;03m#,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#####################################################################\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SMOTENC, SVMSMOTE\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "##################### ALL ARTERY TO ALL DIAGNOSIS #################\n",
        "\n",
        "#Define Input/ Output (array type)\n",
        "feature = base.drop(labels=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_train = base['Plaque'].values\n",
        "X_test = follow.drop(columns=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_test = follow['Plaque'].values\n",
        "\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "smote_nc = SVMSMOTE(random_state=0)\n",
        "method = smote_nc\n",
        "X_resampled, y_resampled = method.fit_resample(X_train, y_train)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "unique_train, counts_train = np.unique(y_resampled, return_counts=True)\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled, y_resampled)\n",
        "print_feature(model, feature)\n",
        "\n",
        "#prediction\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f36f32c",
      "metadata": {
        "id": "5f36f32c"
      },
      "outputs": [],
      "source": [
        "###################### 10 fold ######################\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, f1_score\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imblearn_Pipeline\n",
        "\n",
        "#Define Input/ Output (array type)\n",
        "feature = base.drop(labels=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "# Your data preparation\n",
        "X_train = base.drop(columns=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_train = base['Plaque'].values\n",
        "X_test = follow.drop(columns=['PA_UIKey','Plaque','Severity','FOLLOW','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_test = follow['Plaque'].values\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define model\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,\n",
        "                           l2_leaf_reg=3.0,\n",
        "                           loss_function='Logloss',\n",
        "                           rsm=0.8,\n",
        "                           verbose=100,\n",
        "                           early_stopping_rounds=50)\n",
        "\n",
        "# Define evaluation metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'auc': make_scorer(roc_auc_score, needs_proba=True),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "# Set up 10-fold cross-validation\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "\n",
        "# Use a pipeline for scaling and oversampling\n",
        "pipeline = imblearn_Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(random_state=0)),\n",
        "    ('classifier', model)\n",
        "])\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "\n",
        "# Print results\n",
        "print(f\"{cv_results['test_accuracy']:.4f}\")\n",
        "print(f\"{cv_results['test_auc']:.4f}\")\n",
        "\n",
        "print(f'Cross-Validation Accuracy: {np.mean(cv_results[\"test_accuracy\"]):.4f} ± {np.std(cv_results[\"test_accuracy\"]):.4f}')\n",
        "print(f'Cross-Validation AUC: {np.mean(cv_results[\"test_auc\"]):.4f} ± {np.std(cv_results[\"test_auc\"]):.4f}')\n",
        "print(f'Cross-Validation F1 Score: {np.mean(cv_results[\"test_f1\"]):.4f} ± {np.std(cv_results[\"test_f1\"]):.4f}')\n",
        "\n",
        "# Train final model on entire dataset\n",
        "pipeline.fit(X, y)\n",
        "print_feature(model, feature)\n",
        "# Predictions on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "probability_predictions = pipeline.predict_proba(X_test)\n",
        "\n",
        "# Compute metrics for test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, probability_predictions[:, 1])\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print('--------------------REPORT---------------------')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'AUC: {auc:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2de768",
      "metadata": {
        "id": "2b2de768"
      },
      "outputs": [],
      "source": [
        "##################### ALL ARTERY TO Apoplexia #################\n",
        "\n",
        "#Define Input/ Output (array type)\n",
        "feature = base.drop(labels=['Severity','FOLLOW','APOPLEXIA_SELF','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['Severity','FOLLOW','APOPLEXIA_SELF','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_train = base['APOPLEXIA_SELF'].values\n",
        "X_test = follow.drop(columns=['Severity','FOLLOW','APOPLEXIA_SELF','RCCA_STATUS','右ICA正常與否','左CCA正常與否','左ICA正常與否']).values\n",
        "y_test = follow['APOPLEXIA_SELF'].values\n",
        "\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "# Count the number of 1s in y_train\n",
        "count_ones = sum(y_train)\n",
        "count_zeros = len(y_train) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "# smote_nc = SVMSMOTE(random_state=0)\n",
        "# method = smote_nc\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled,  y_resampled )\n",
        "fs_df = print_feature(model, feature)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X_resampled,  y_resampled, cv=5, scoring='f1')\n",
        "print(f\"Cross-validated F1 scores: {scores}\")\n",
        "\n",
        "#prediction\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fit model using each importance as a threshold\n",
        "thresholds = sort(model.feature_importances_ )[::-1]\n",
        "\n",
        "fs = []\n",
        "for thresh in thresholds:\n",
        "    if thresh <=0:\n",
        "        break\n",
        "    # select features using threshold\n",
        "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "    select_X_train = selection.transform(X_resampled)\n",
        "\n",
        "    # train model\n",
        "    selection_model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "    selection_model.fit(select_X_train, y_train)\n",
        "\n",
        "    # eval model\n",
        "    select_X_test = selection.transform(X_test)\n",
        "    y_pred = selection_model.predict(select_X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "#     fs.append((thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "#     fs_df = pd.DataFrame(fs, columns=['Thresh','Feature Counts', 'Accuracy'])\n",
        "    fs_df.to_csv('Apoplexia_feature_selection.csv')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e3961e",
      "metadata": {
        "id": "95e3961e"
      },
      "outputs": [],
      "source": [
        "fcounts = fs_df['Feature Counts'].to_list()\n",
        "acc = fs_df['Accuracy'].to_list()\n",
        "\n",
        "# Convert 1D data to a 2D format\n",
        "data_2d = np.array(acc).reshape(1, -1)  # Single-row matrix\n",
        "accuracy_data_normalized = data_2d / 100\n",
        "accuracy_data_rounded = np.round(accuracy_data_normalized, 2)\n",
        "data_2d = accuracy_data_rounded.T\n",
        "# Define custom labels for x and y axes\n",
        "xticks_labels = ['Accuracy']\n",
        "yticks_labels = fcounts\n",
        "\n",
        "plt.figure(figsize=(1, 20))\n",
        "# Create a heatmap\n",
        "plt.xticks(fontsize=14)\n",
        "sns.heatmap(data_2d, cmap='crest', annot=True, cbar=True, xticklabels=xticks_labels, yticklabels=yticks_labels)\n",
        "plt.title('Accuracy of each artery')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099eeac8",
      "metadata": {
        "id": "099eeac8"
      },
      "outputs": [],
      "source": [
        "################# RCCA ################################\n",
        "#Define Input/ Output (array type)\n",
        "rcca = df.iloc[:, list(range(0, 10)) + list(range(35, 59))]\n",
        "rcca['RCCA_STATUS'] = rcca['RCCA_STATUS'].replace('異常', 1)\n",
        "rcca['RCCA_STATUS'] = rcca['RCCA_STATUS'].replace('正常', 0)\n",
        "rcca['RCCA_STATUS'] = rcca['RCCA_STATUS'].replace('1.5', 1)\n",
        "print(df.columns)\n",
        "print(rcca.columns)\n",
        "\n",
        "base = rcca[rcca['FOLLOW']=='Baseline']\n",
        "follow = rcca[rcca['FOLLOW']=='Follow 1']\n",
        "\n",
        "feature = base.drop(labels=['PA_UIKey','Severity','FOLLOW','RCCA_STATUS'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "print(feature)\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['PA_UIKey','Severity','FOLLOW','RCCA_STATUS']).values\n",
        "y_train = base['RCCA_STATUS'].values\n",
        "X_test = follow.drop(columns=['PA_UIKey','Severity','FOLLOW','RCCA_STATUS']).values\n",
        "y_test = follow['RCCA_STATUS'].values\n",
        "print(y_train)\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_train)\n",
        "count_zeros = len(y_train) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "# smote_nc = SVMSMOTE(random_state=0)\n",
        "# method = smote_nc\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "fs_df = print_feature(model, feature)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fit model using each importance as a threshold\n",
        "thresholds = sort(model.feature_importances_ )[::-1]\n",
        "\n",
        "fs = []\n",
        "for thresh in thresholds:\n",
        "    if thresh <=0:\n",
        "        break\n",
        "    # select features using threshold\n",
        "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "    select_X_train = selection.transform(X_train)\n",
        "\n",
        "    # train model\n",
        "    selection_model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "    selection_model.fit(select_X_train, y_train)\n",
        "\n",
        "    # eval model\n",
        "    select_X_test = selection.transform(X_test)\n",
        "    y_pred = selection_model.predict(select_X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fs.append((thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    fs_df.to_csv('RCCA_feature_selection.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99ede56",
      "metadata": {
        "id": "e99ede56"
      },
      "outputs": [],
      "source": [
        "################# RICA ################################\n",
        "#Define Input/ Output (array type)\n",
        "\n",
        "rcca = df.iloc[:, list(range(10, 18)) + list(range(35, 59))]\n",
        "rcca['右ICA正常與否'] = rcca['右ICA正常與否'].replace('異常', 1)\n",
        "rcca['右ICA正常與否'] = rcca['右ICA正常與否'].replace('正常', 0)\n",
        "rcca['右ICA正常與否'] = rcca['右ICA正常與否'].replace('1.5', 1)\n",
        "print(df.columns)\n",
        "print(rcca.columns)\n",
        "\n",
        "base = rcca[rcca['FOLLOW']=='Baseline']\n",
        "follow = rcca[rcca['FOLLOW']=='Follow 1']\n",
        "\n",
        "feature = base.drop(labels=['Severity','FOLLOW','右ICA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "print(feature)\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['Severity','FOLLOW','右ICA正常與否']).values\n",
        "y_train = base['右ICA正常與否'].values\n",
        "X_test = follow.drop(columns=['Severity','FOLLOW','右ICA正常與否']).values\n",
        "y_test = follow['右ICA正常與否'].values\n",
        "print(y_train)\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_train)\n",
        "count_zeros = len(y_train) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "# smote_nc = SVMSMOTE(random_state=0)\n",
        "# method = smote_nc\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", counts_train[unique_train == 1][0])\n",
        "print(\"y_train = 0:\", counts_train[unique_train == 0][0])\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "fs_df = print_feature(model, feature)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fit model using each importance as a threshold\n",
        "thresholds = sort(model.feature_importances_ )[::-1]\n",
        "\n",
        "fs = []\n",
        "for thresh in thresholds:\n",
        "    if thresh <=0:\n",
        "        break\n",
        "    # select features using threshold\n",
        "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "    select_X_train = selection.transform(X_train)\n",
        "\n",
        "    # train model\n",
        "    selection_model = CatBoostClassifier(iterations=100,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "    selection_model.fit(select_X_train, y_train)\n",
        "\n",
        "    # eval model\n",
        "    select_X_test = selection.transform(X_test)\n",
        "    y_pred = selection_model.predict(select_X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fs.append((thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    fs_df.to_csv('RICA_feature_selection.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcaa3201",
      "metadata": {
        "id": "fcaa3201"
      },
      "outputs": [],
      "source": [
        "################# LCCA ################################\n",
        "#Define Input/ Output (array type)\n",
        "lcca = df.iloc[:, list(range(18, 27)) + list(range(35, 59))]\n",
        "lcca = lcca.dropna()\n",
        "lcca['左CCA正常與否'] = lcca['左CCA正常與否'].replace('異常', 1)\n",
        "lcca['左CCA正常與否'] =lcca['左CCA正常與否'].replace('正常', 0)\n",
        "lcca['左CCA正常與否'] = lcca['左CCA正常與否'].replace('異常無', 1)\n",
        "\n",
        "print(df.columns)\n",
        "print(lcca.columns)\n",
        "\n",
        "base = lcca[lcca['FOLLOW']=='Baseline']\n",
        "follow = lcca[lcca['FOLLOW']=='Follow 1']\n",
        "\n",
        "feature = base.drop(labels=['Severity','FOLLOW','左CCA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "print(feature)\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['Severity','FOLLOW','左CCA正常與否']).values\n",
        "y_train = base['左CCA正常與否'].values\n",
        "X_test = follow.drop(columns=['Severity','FOLLOW','左CCA正常與否']).values\n",
        "y_test = follow['左CCA正常與否'].values\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Check if there are values other than 0 and 1\n",
        "unique_values = base['左CCA正常與否'].unique()\n",
        "non_binary_values = [val for val in unique_values if val not in (0, 1)]\n",
        "if non_binary_values:\n",
        "    print(f\"y_train contains values other than 0 and 1: {non_binary_values}\")\n",
        "else:\n",
        "    print(\"y_train contains only 0 and 1.\")\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_train)\n",
        "count_zeros = len(y_train) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "# smote_nc = SVMSMOTE(random_state=0)\n",
        "# method = smote_nc\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_resampled)\n",
        "count_zeros = len(y_resampled) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "fs_df = print_feature(model, feature)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fit model using each importance as a threshold\n",
        "thresholds = sort(model.feature_importances_ )[::-1]\n",
        "\n",
        "fs = []\n",
        "for thresh in thresholds:\n",
        "    if thresh <=0:\n",
        "        break\n",
        "    # select features using threshold\n",
        "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "    select_X_train = selection.transform(X_train)\n",
        "\n",
        "    # train model\n",
        "    selection_model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "    selection_model.fit(select_X_train, y_train)\n",
        "\n",
        "    # eval model\n",
        "    select_X_test = selection.transform(X_test)\n",
        "    y_pred = selection_model.predict(select_X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fs.append((thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    fs_df.to_csv('LCCA_feature_selection.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d285aa1b",
      "metadata": {
        "id": "d285aa1b"
      },
      "outputs": [],
      "source": [
        "################# LICA ################################\n",
        "\n",
        "#Define Input/ Output (array type)\n",
        "lica = df.iloc[:, list(range(27, 35)) + list(range(35, 59))]\n",
        "lica = lica.dropna()\n",
        "lica['左ICA正常與否'] = lica['左ICA正常與否'].replace('異常', 1)\n",
        "lica['左ICA正常與否'] = lica['左ICA正常與否'].replace('正常', 0)\n",
        "lica['左ICA正常與否'] = lica['左ICA正常與否'].replace('異常無', 1)\n",
        "\n",
        "print(df.columns)\n",
        "print(lica.columns)\n",
        "\n",
        "base = lica[lica['FOLLOW']=='Baseline']\n",
        "follow = lica[lica['FOLLOW']=='Follow 1']\n",
        "\n",
        "feature = base.drop(labels=['Severity','FOLLOW','左ICA正常與否'],axis=1)\n",
        "feature = feature.columns.to_list()\n",
        "print(feature)\n",
        "\n",
        "#df = df.drop(columns=['SIT_3_SYSTOLIC_PRESSURE', 'SIT_3_DIASTOLIC_PRESSURE','SMK_2ND_PLACE4_HR','RCCA_Plaque','RICA_Plaque','LCCA_Plaque','LICA_Plaque'\n",
        "                     #,'PA_UIKey','SURVEY_DATE','Release_No','頸超總結'])\n",
        "#####################################################################\n",
        "X_train = base.drop(columns=['Severity','FOLLOW','左ICA正常與否']).values\n",
        "y_train = base['左ICA正常與否'].values\n",
        "X_test = follow.drop(columns=['Severity','FOLLOW','左ICA正常與否']).values\n",
        "y_test = follow['左ICA正常與否'].values\n",
        "\n",
        "# Combine X_train and X_test, and y_train and y_test\n",
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "# Check if there are values other than 0 and 1\n",
        "unique_values = base['左ICA正常與否'].unique()\n",
        "non_binary_values = [val for val in unique_values if val not in (0, 1)]\n",
        "if non_binary_values:\n",
        "    print(f\"y_train contains values other than 0 and 1: {non_binary_values}\")\n",
        "else:\n",
        "    print(\"y_train contains only 0 and 1.\")\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_train)\n",
        "count_zeros = len(y_train) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Oversample the PCA-transformed training data\n",
        "from imblearn.over_sampling import SMOTE,SMOTEN\n",
        "\n",
        "# smote_nc = SVMSMOTE(random_state=0)\n",
        "# method = smote_nc\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "# Count the occurrences of 1s and 0s in y_train\n",
        "count_ones = sum(y_resampled)\n",
        "count_zeros = len(y_resampled) - count_ones\n",
        "# Print the counts\n",
        "print(\"y_train = 1:\", count_ones)\n",
        "print(\"y_train = 0:\", count_zeros)\n",
        "\n",
        "\n",
        "#####################################################################\n",
        "# Check the dimensions of X\n",
        "print(\"Dimensions of X train:\", X_resampled.shape)\n",
        "print(\"Dimensions of X test:\", X_test.shape)\n",
        "\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "probability_predictions = model.predict_proba(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "fs_df = print_feature(model, feature)\n",
        "\n",
        "#評估報表\n",
        "print('--------------------REPORT: {}---------------------\\n')\n",
        "print(classification_report(y_test, y_pred))\n",
        "#################################################################################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n",
        "\n",
        "# Compute the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(fpr, tpr, color='seagreen', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='midnightblue', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right',fontsize =16)\n",
        "plt.show()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fit model using each importance as a threshold\n",
        "thresholds = sort(model.feature_importances_ )[::-1]\n",
        "\n",
        "fs = []\n",
        "for thresh in thresholds:\n",
        "    if thresh <=0:\n",
        "        break\n",
        "    # select features using threshold\n",
        "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "    select_X_train = selection.transform(X_train)\n",
        "\n",
        "    # train model\n",
        "    selection_model = CatBoostClassifier(iterations=1000,\n",
        "                           learning_rate=0.01,\n",
        "                           depth=6,l2_leaf_reg=3.0,\n",
        "                           loss_function='MultiClass',rsm=0.8,verbose=100,\n",
        "                          early_stopping_rounds=50 )\n",
        "    selection_model.fit(select_X_train, y_train)\n",
        "\n",
        "    # eval model\n",
        "    select_X_test = selection.transform(X_test)\n",
        "    y_pred = selection_model.predict(select_X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fs.append((thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
        "    fs_df.to_csv('LICA_feature_selection.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5786d188",
      "metadata": {
        "id": "5786d188"
      },
      "outputs": [],
      "source": [
        "# Merge df1 and df2 on 'ID'\n",
        "df1 = pd.read_csv('RCCA_feature_selection.csv')\n",
        "df2 = pd.read_csv('RICA_feature_selection.csv')\n",
        "df3 = pd.read_csv('LCCA_feature_selection.csv')\n",
        "df4 = pd.read_csv('LICA_feature_selection.csv')\n",
        "merged_df = pd.merge(df1, df2, on='Feature Name', how='outer')\n",
        "\n",
        "# Merge the result with df3\n",
        "merged_df = pd.merge(merged_df, df3, on='Feature Name', how='outer')\n",
        "\n",
        "# Merge the result with df4\n",
        "merged_df = pd.merge(merged_df, df4, on='Feature Name', how='outer')\n",
        "\n",
        "merged_df.to_csv('feature_selection.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fb88a3",
      "metadata": {
        "id": "a2fb88a3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}